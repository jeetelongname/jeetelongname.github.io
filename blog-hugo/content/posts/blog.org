#+HUGO_BASE_DIR: ~/code/web/website/blog-hugo
#+HUGO_SECTION: posts
#+hugo_front_matter_format: yaml
#+STARTUP: show2levels

* Posts
** DONE 2am paella :cooking:cheap:easy:
:PROPERTIES:
:EXPORT_FILE_NAME: 2am-paella
:EXPORT_DATE: 2022-03-03
:END:
*** Introduction
Its 2am and your hungry, but you look in the noodle cupboard and you realise
your out of instant ramen ðŸ˜±.
#+hugo: more
Here is a quick way to eat some vegetables, prep some soul
filling food and have nummies done in 20ish minutes (which is not bad for something
from scratch). This is not a traditional recipe, It kinda is similar but its not
authentic in any way, shape or form.

**** The things you will use
***** Ingredience
- rice, about a cup :: this is the base and pretty non negotiable, pasta may work in a
  pinch but it will throw off some ratios and be harder to manage.
- vegetables :: this can be anything, except maybe lettuce, here is what I
  used.
  - mushrooms of some kind.
  - an onion, I use spring onions as it also work as a garnish.
  - bell peppers
  - and sweet potatoes but again anything will work.
- spices :: I used turmeric, chilli flakes garlic and garam marsala as that's what i had
  on hand but if you had some harisa powder it would work really well here. But
  play with the flavours. Its a blank canvas.
- protein :: now this is kinda optional as the things mentioned before would
  work wonders on its own but if you have chicken pieces or something
  similar tossing them in will not hurt. That being said if you do I would try
  and keep the skin (if there is any) above the water line to help browning
  later.

***** utensils
- chopping board and knife
- serving dish :: i.e plate
- oven safe pan :: this is because we will stick it under the broiler but if you
  don't have one then this dish will still be good without broiling the top.
**** the basic method
0. preheat the broiler
1. add some oil to a pan and start to fry your protein.
   this is to give it a head start and prevent some nasty smells (boiling
   unbrowned meat smells like corpses).
2. start prepping your veg. you can do this before but this saves on a little
   time. Cut them into manageable pieces, they don't need to be clean or even as
   it will all be boiled till tender.
3. add the veg into the pan and fry it all together.
4. add in rice to toast as well as the spices before, fry till they are fragrant.
5. add water to the pan and boil till rice is soft, keep topping the water up as needed.
   - While its boiling you can basically wash up the chopping board.
6. once rice is cooked, turn off the heat and put the pan under the hot broiler,
   cook until the top is brown (this will happen quick so watch it closely).
7. eat. Optionally garnish with something green, green bit on spring onions, coriander leaves
   go nuts!

*** Finishing thoughts
This is a fun little dish that acts as a blank canvas. chuck in whatever you
have and let it simmer for a bit and your done!
** TODO The privacy of public transport
:PROPERTIES:
:EXPORT_FILE_NAME: privacy_public_transport
:EXPORT_DATE: 2022-04-13
:END:
We as a world need to pick up public transport. Not only are they usually leagues
better for the environment compared to cars they are also more space efficient
and lead to quieter, safer and nicer cities.

But this comes at the cost of a few things (some of which can be fixed with
funding and time) but one of them seems almost un refutable. The idea of privacy
on transport. Now while in a theoretical sense this is true you are essentially
in a crowed of people any of which could approach you, in practice its one of
the more private experiences I have had.

*** The Car
The car is meant to be the epitome of freedom and privacy, go wherever you want
with no need to interact with people. But in this case there is the lack of
something. Either you are the driver in which case you are not free to do things
like work, read or sleep and in a sense the time is wasted driving. Or you are
a passenger in which case you are also not free (unless you are being driven
around which is out of the reach of 90% of the population). You are attached to
the social graces that come with human interaction in a confined space or are in
an even more mundane situation where you are the navigator or other auxiliary
function within the journey.

In either sense your not free to use that time in
some kind of productive manner and this will only get worse with more people in
this confined space, I say this as someone who has had one to many packed road
trips and dead butt cheeks.

*** Public Transport
With public transport I don't have this to worry about. When I am travelling
alone (which is most of the time). I am free to do what I want. I usually read
but am free to do some light work, free to rest to some degree as well. In reality I do
not have to talk to people other than the bus driver or odd ticket collector.
Other people are not a problem as they don't want to talk to me as much as I
don't want to talk to them. This is much more private and much more free,
especially with the ability to buy tickets on my phone the amount of interaction
with other human life goes down to near zero. And the interaction that does
happen is quick or pleasant enough that I enjoy it.

This being said this is not a blanket privacy, you can't break down on a train
the same way you can in a car, nor could you use a train as a home when camping
or when times are tough. Its not a private compartment but it is a nice social
interaction bubble which in a lot of contexts is all people need.

*** Conclusion
Public Transport is similar to a cafe. When you sit down at a table even though
you are in a crowd you are alone, and unless you are being loud or (for lack of
a better term) /weird/ then you are left alone for the most part. This privacy
in public in a way is freeing and something that becomes a nice to use after a
while.
** TODO Pacific Rim, Mecha and Charm :movies:opinion:
:PROPERTIES:
:EXPORT_DATE: 2022-05-27
:EXPORT_FILE_NAME: pacific-rim-op-ed
:END:
Pacific Rim is one of my favorite movies, not because it says something deep
about society, or the human soul, not because its even that well made. But
because its a direct, witty, campy movie that opens up my inner 9 year old in
more ways than one. Its a deeply fun and interesting movie that almost forces
you back to being that child that loves the carnal pleasure of citys being
destroyed by biggest baddest robot fighting the biggest baddest robots.

*** The babble
and boy does this movie have a lot. Its a massive word soup that is thrown at
you hot and fast.
#+begin_quote
Solid iron hull, no alloys.
Forty engine blocks per muscle strand.
Hyper-torque driver for every limb
and a new fluid synapse system.
#+end_quote
This almost forces you to just let your mind run wild, there is nothing to
compare it against so we are forced to run with the discriptors, we start going
to bigger numbers cooler words and in essence, we dumb down our thought. This
does not stop mind you. We are bombarded with it throughout the movie. It is
never meant to be focused on, this is not a technical movie that wants to build
a technical world. but its use makes us

*** The Mechs
Or Jaegers as they are known. meaning Hunter in German they are less
*** The Characters
*** The Charm
** DONE Dr Strange: Movie of madness :movies:opinion:spoilers:
:PROPERTIES:
:EXPORT_FILE_NAME: dr-strange-critique
:EXPORT_DATE: 2022-05-31
:END:
I recently, like a lot of people, watched the new Dr Strange movie. I found
it... underwhelming to say the least. Even though it looked great I left that
movie hall feeling like I just watched an underused mess. It was almost not as
fun as having to deal with the ire of my family, as I was the one who chose the
movie...

BTW this is an adaptation from a long discord message I posted in the [[https://doomemacs.org/discord][doom emacs
discord server]] so... Hi Lejon! I guess.

***** *Spoilers ahead, you have been warned*

*** The movie
In a word it felt like an underused cobbled together mess.
I watched it in 2D, this meant that I did not get the face punching 3d affects
and most of the spectacle of the story was squarely on the story (though the
movie still looked great). I think with better writing not only would the themes
and concepts have felt more solid but we would have more use (and proper use) of
characters.

The villain introduction relied on you watching Wanda Vision for the arc to make
sense, otherwise if you are a casual, coming straight from endgame it felt very
much out of left field.

Characters that were teased at in the first Dr Strange, principally Mordo, a
character who was teased as the villain for the sequel was not even shown. We
instead get a Mordo that is not the one that has been built up and is then
thrown away after a mild fist fight with little resolution to what he means to
Strange. This lack of continuity from its principal prequel felt like a pressure
release valve going off. All bets are off and all tension is cut. This will not
translate over to any third movie as it would have been too long. the first
movie was released in 2016... 6 years ago. another movie will not be coming for a
while and by that time at least my psyche would have moved on. Mordo and his
build up would have been wasted.

The Illuminati (why the illuminati??) present in universe 838 were comprised of the
first cannon introductions of both the Fantastic Four and the Xmen in the MCU
(M?) both of which were over very quickly on screen, it felt like "oh this is a
thing that will be coming in the later movies but we want to tease it now". Then
you also have Peggy Carter as Captain Britain (or whatever), principally a call
back to What If but if you did not watch that, it was a gag. A lesser example of
the problem I had with Wanda's arc.

*** Themes from a box

Themes are presented such as happiness, motherhood, loss and confidence.
None of these felt explored in any satisfactory way.
Happiness was not really dealt with, Strange was just kinda asked "are you
happy?" and lied through his teeth, this then came up near the end as well when
evil Strange number 3 asked the same question and then they started fighting
with music notes. It was kinda resolved with the monologue to 838 Christine but
in a cheesy way, not in anything that felt good for the character. It felt like
the cliche line and a cliche theme that did not do much for our character. I
feel like the movie would not have been different if it was not included.

Motherhood was better in this regard. It gave Wanda's sacrifice weight in a
sense and was played in little bits though out the movie, as she dreamed and dream
walked. It added to her ending seeing her actions come to a head and see how she
will never be a mother to any child she abducts. It was a good scene and a good
theme.

Confidence on the other hand while being intertwined with happiness also takes a
lot of traits from it (not really but the parallels are there). it did not feel
dealt with in any real sense though out the movie and it just came to the head
that was the power of friendship ending where the protagonist learns to believe
in themselves and then girlbosses scarlet witch. It felt rushed with no real
build up.

*** Multiverse of... not much?

The concept of multiverse was very much underused with us not getting a chance
to really see it. This does not mean I want to see a massive amount of
universes but want to see /the concept/. Otherwise it does not become a
distinct thing, a concept the movie plays with, but a plot device that does
nothing but give our characters reason to move (editor's note: a MacGuffin
(Thanks Lejon)), as well as fuel this power of
love story ending (I know its not actually a power of love ending, I am taking a
little bit of piss)
Some may say It was never explained in any real way which reflects
the unknown nature of it to our protagonists, but even still with this it does
not feel distinct in any meaningful way
*** What this says about the MCU

This speaks to a bigger problem I saw in endgame but think this movie
exemplifies, The MCU has gotten too big to be cohesive. Most of the movie felt
like callbacks, teasers and set up with actual substance being lost. It leads to
a movie that felt hollow in many senses, gravity has been lost and points of
interest have become little more than lore points for the overall arc in
phase 5. As it grows if you want to stay in the loop and understand most movies
fully, you need to watch everything that comes before, its getting to the point
where there are entire sub markets writing up plot summaries so that you can
understand the movie. This essentially excludes the casual from the franchises
they enjoy, People may only tune in for the movies they care about (for me those
being the spiderman and Dr Strange and maybe Thor) they are left out. Now I
could go on about how this is all to drive up profit and coerce people into
going to every movie and watching all the shows on Disney+ but that's for another
day.

Part of the magic of the first set of movies was that it was a small rag tag
team that had there own introductions, each movie added context but also did not
become required reading to understand in full.

Endgame was the beginning of this. This movie is the beginning of the end.

** DONE Moving to Wayland! Login shell lambasting :gnome:wayland:fix:hack:
:PROPERTIES:
:EXPORT_FILE_NAME: moving-to-wayland1
:EXPORT_DATE: 2022-06-16
:END:
*** The problem
I have been trying to move to Wayland for the past year. The call of gestures,
less artifacting and just the /hype/ had me spell bound. The problem was,
GNOME, my DE of choice, decided to make what I think is the asinine choice to not
start the DE in a login shell. All this meant was my ~.profile~ never runs and my nix
environment never get set up. This is a deal breaker for me because I have
programs I use every day (principally emacs) which I can now not access.

This is not a problem though! GNOME has thought of everything! you can now
/declarativly/ declare all the environment variables you want with an
~environment.d/*.conf~ file!.. Oh wait. I can't run shell scripts with that...
That's
the reason I could not use my nix programs, nix sets its environment using a set of external shell
scripts that can and do change as nix installs and removes packages. This is not
a problem for a login shell as it just runs them like any normal sourced file.
But you can't run scripts in this conf file meaning nix stays unusable.

*** What was my solution then?
Well my first port of call was of course to force GNOME to start a Wayland
session in a login shell. After all thats how other people get other Wayland
environments to respect there ~.profiles~. Ez slap a ~-l~ in the exec call of
whatever program starts GNOME and we are golden right... Well no. While you can
wiggle GNOME into running a login shell, it seems its allergic to running in a
Wayland session. I am not sure of the black magic GNOME does to start its
Wayland session but its above my pay grade.
That being said I have tried most things from fiddling with the xsession file to
pass in a ~-l~ argument, to making my own slightly modified ~gnome-session~
start up script. They either did not spawn a Wayland session, or did not load my
~.profile~ (or in one entertaining case did not launch GNOME at all, I just had
a bare x display server). In any sense it did not work and it made me sad.

**** The actual solution
But thanks to Flat on the doom emacs discord server, for breaking me out of the
rut I was in, and inspiration from the [[https://github.com/doomemacs/doomemacs][doom env command]]
Instead of trying to force GNOME into the login shell, bring my login shell
(more specifically my environment) to GNOME!

This is where I ask you to flash back to 20 seconds ago
where I mentioned the ~environment.d/*.conf~ files. Well all we are doing is setting
environment variables with our ~.profile~, if we could capture all of the
environment variables my ~.profile~ sets and pipe that into a conf file We would
be done! In a nice list it would take three things:

- an empty environment to actually see /exactly/ what is being set
- A command to run my .profile
- a command to print all the set environment variables

The first and last are actually handled by the ~env~ command!  Just call it with
the ~-i~ flag and it starts with and empty environment! Then call it at the end
to get my list! Now to read my .profile.
Turns out we can just call ~sh~ with the ~-l~ flag to start a login shell, like I
have been wanting to do with GNOME! This leads to this very nice one liner which
I can then redirect into a ~.conf~ file like so.
#+begin_src shell
env -i HOME=/home/jeet sh -l -c env > ~/.config/environment.d/profile.conf
#+end_src

I don't even have to do any parsing as it's already in the syntax the
~environment.d~ expects!
And that was it! Just that one liner and a log out and I can finally use Wayland!
Its such a simple hack in retrospect. All I would need to do now is hook this
into running at the tail end of a nix update to recapture my environment and
this hack would be seemless!

*** Conclusion
The fact I have had to do this in the first place feels silly. I love GNOME and
I can understand why the devs would want to move to a more intergrated system in
a sense. Does not stop me from being mad I had to wait a year to be able to use
Wayland full time. Or that I have had to spend so much time trying to figure out
how to wiggle /my not unpopular use case/ into something usable. In any case the fix is
there, even if its not preferred, and I can move onto bigger things! This may be
the beginning of a set of posts about Wayland and my adaptations to it so stay tuned!

And if you did manage to actually get a GNOME Wayland session to start in a login
shell though please do reach out!

** TODO Doom, Emacs and Communication
:PROPERTIES:
:EXPORT_FILE_NAME: doom-communication
:EXPORT_DATE: 2022-08-20
:END:
Recently Protesilaos, also known as Prot, wrote a blog post detailing [[https://protesilaos.com/codelog/2022-08-04-doom-git-gutter-modus-themes/][how Dooms
configuration of Git Gutter constituted a soft fork]] in so far it broke his modus
themes. I will not detail what happened here as Prot does a fine job of that
([[https://github.com/doomemacs/doomemacs/commit/cd9bc5a1fdaacc41b7e0f05012509ba2814cef89][and as it was addressed upstream]]).
The problem with what happened here is that nowhere in this process the doom
project was informed of this problem. In this case instead of notifying the doom
project It was diagnosed and documented in the manual. The doom project finally
came to know when said blog post was posted and steps were taken within a timely
manner. With more steps being worked on to address the problems stated.

This then happens again in the release of [[https://protesilaos.com/codelog/2022-08-19-modus-themes-2-6-0/][modus themes 2.6.0]] Where the theme
drops support for [[https://github.com/hlissner/emacs-solaire-mode][solaire mode]] on the grounds that doom users opt into using the
package without knowing, thus leading to the themes being sub par out of the box
(again I recommend reading the release log linked above). This is not to suggest
that themes need to support solaire mode ([[https://github.com/hlissner/emacs-solaire-mode/commit/56f6d9ea9cfa3f3fd5d64d995381fdb0da898b28][and solaire works in such a way to
deactivate when a theme does not support it]]) but again neither the doom
project or the maintainer of solaire (in this case the same person) got
notified and again found out through this code log.

In a word this is not a good way to act. The doom project cannot stay on top of
how every package in the emacs ecosystem will interact with doom and to ask of
that is silly.

I can empathise with package maintainers, getting issues they
can't diagnose because the problem is not with there package but with how that
package interacts with doom. But the solution here is not to silently move on
(only for it to resurface later on) but to talk to the project. If a problem is
coming up then make an issue on the bug tracker, discourse or shoot a message to
us in the discord . From there we can work to a solution that both parties
can accept, In the former example it was a simple matter of gating the
config. The latter could have either been solved on the solaire side or on the
doom side (in this case its the same maintainer). The solutions are to be had
if only the community talked with us about these issues.

*** Dooms relationship to the wider community
It makes sense to discuss how doom relates to the rest of the community as it's
special in this regard.
In a phrase doom is a middle man, taking packages and
configuring them for end users. This means for us that we need to have
relationships with both sides of this equation, and to some degree we do. We
have package maintainers who discuss problems with us as we develop modules
using there packages. We also have doom users who also maintain packages that
then get put back into doom!.


*** Who the forums are for
In a word, Everyone. This is an area of active improvement for us as we
introduce new constructs to make sure that maintainers can voice there /things/
with us in a constructive manner. But this should not stop maintainers talking
to us, if your package is interacting badly with doom, raise it on the discourse
or github. If you want to discuss something indepth, join us on the discord
(eventually there will also be a matrix room if thats more your style). The key
here being the forums are for everyone and not just users.

** DONE I finally understand monads and now I will write about it :haskell:programming:
CLOSED: [2022-11-23 Wed 05:53]
:PROPERTIES:
:EXPORT_DATE: 2022-11-07
:EXPORT_FILE_NAME: understanding-monads
:END:
After a lot of struggle I finally understand monads and why they are useful.
This is less an explainer and more of a write up of my understanding. In any
case let us get started.

*** So what is a monad?
A monad is a datatype that can use =>>==, You can call it ~bind~ or ~then~ with
the latter name leading into what it does.
Here is its type.
#+begin_src haskell
(>>=) :: m a -> (a -> m b) -> m b
#+end_src
This function takes in a context of =m a=, then a function which transforms that
inner value, returning that transformed value in the same context.
#+begin_src haskell :results output
print $ Just 1 >>= return . (+1)
print $ Just 2 >>= return . (+1)
#+end_src

: Just 2
: Just 3

This allows for many operations to be chained together, as the return value of
the first becomes the input of the next.

#+begin_src haskell
print $ Just 1 >>= return . (+1) >>= return . (+1)
#+end_src

: Just 3

**** Do notation
This chaining of operations looks a lot like imperative programming. This is in
part why ~do~ notation exists. If we were to use IO (which is a value
contained in the context that it came from an input output system.)
This
#+begin_src haskell
print "Hello, what is your name?" >>= \_ -> getLine >>= \name -> print $ "Hello " ++ name
#+end_src
Turns into
#+begin_src haskell :results output
main = do
  print "Hello, what is your name?"
  name <- getLine
  print ("Hello " ++ name)
#+end_src
Which should look pretty familiar to you.
Here is what the python looks like
#+begin_src python
def main():
    print("Hello, what is your name?")
    name = input()
    print("Hello " + name)
#+end_src

*** Okay this is cool and all, but why do we need to implement functor and applicative??
Well when you look at what we are doing, =>>== hides a lot from us.
When we have a look at what functor and applicative add to the
equation we can hopefully see why we need them as well.

*** Functors
A functor is a datatype where we can (f)map the inner value without losing the
outer context.
It gives us the =<$>= operator, otherwise know as fmap.
Its type is

#+begin_src haskell
(<$>) :: (a -> b) -> f a -> f b
#+end_src

This operation takes a function that transforms =type a= into =type b=, and then
a functor of =type a=, it transforms it into a functor of =type=b.
Simple enough.

One little side note, /haskell is curried/ meaning that we can write
something like this =(f <$>)= Which returns a function that takes a functor of
=type a=.
If we say for demonstration that =f= is a function that takes an =Int= and
returns a =String=, our types would look like this.
#+begin_src haskell
f :: Int -> String
(f <$>) :: f Int -> f String
#+end_src
Essentially we have transformed our lowly =f= that can only work on simple types
into a function that works on functors. This is known as a /lift/ operation.
This is important for later.

*** Applicatives
Applictives add a few more operations to the mix, notably =pure= and =<*>=
Here are the types
#+begin_src haskell
pure :: a -> f a
(<*>) :: f (a -> b) -> f a -> f b
#+end_src
Pure is simple enough. It takes a value and "wraps" it into an applicative. This
raises a value and allows us to use it in the applicative space.
=<*>= takes a function wrapped in an applicative and compose it with another
applicative. If you compare its type to that of =<$>= we can see that they are
similar but =<*>= allows us to use a function in a context! this makes it a more
general version of functor.

Also note that
#+begin_src haskell
(f <$>) ::  f Int -> f String
(pure f <*>) :: f Int -> String
#+end_src

**** Why is this useful
Well these operations allow us to compose contexts together, something that was
not possible with just =<$>=
For example lets take =(min <$>)= as an example
#+begin_src haskell
min :: a -> a -> a
(min <$>) :: f a -> f (a -> a)
#+end_src
Here we are using a function that takes two arguments rather than one and here
we can see our problem. We have a function wrapped in a context. /If only there/
/was an operation that allowed us to compose contexts together/.
As we can see the left hand side of this equation has the type of =f (a -> a)=,
the right has the type of =f a= these, which then combine and come to the correct
result.
#+begin_src haskell
min <$> Just 1 <*> Just 2
#+end_src

This scales. Here is a function which takes in three arguments and adds them.
Here we lift f then apply one context. We get back a value which takes in
another context and returns a function within that same context [fn:1] which we can continue to
chain with other values using =<*>=
#+begin_src haskell
f :: a -> a -> a -> a
f a b c = a + b + c

(f <$>) :: f a -> f (a -> a -> a)
(f <$> Just 1 <*>) :: f a -> f (a -> a)
(f <$> Just 1 <*> Just 1 <*>) :: f a -> f a
#+end_src

*** +Bringing+ /Binding/ this all together
So we have the ability to transform the inner value of a context, we have the
ability to compose two or more contexts together. The problem arises when we want to
compute the next context based on the result of the previous. Look again at the
type of =<*>=
#+begin_src haskell
(<*>) :: f (a -> b) -> f a -> f b
#+end_src
we know the end goal of this computation as all =<*>= is doing is satsfying the contexed
function. This limits us to computations where we can reason about the end
result. What about a computation where we can't, where we need to think about the
last computation before we move on. This is a power monads have.

Lets revist the type of =>>==
#+begin_src haskell
(>>=) :: m a -> (a -> m b) -> m b
#+end_src
The first argument is a contexted value, You can reason about it like its some
kind of computation. This computation is then "unwrapped" and passed into a
function which crucially /can decide what to do/. We do not need to think about
whatever end goal we want right at the beginning, we can go as the wind tells us,
so to speak. This is useful in places we need to parse some kind of contextual
information, for
example a context filled language such as some markup languages, [[https://orgmode.org/][including the
one I am currently writing this post in]].
*** A monad in plain sight
So we have discussed what all of these things are but lets discuss a real world
monad, One that you probably have already used. The Async Monad!

Yes if you have done Async programming then you have used a monad. Lets
have a look at an example.
#+begin_src js
fetch(`http://localhost:8080/some-data`).then(response => {
    if (response.ok) {
        response.text().then(text => JSON.parse(text))
    }
})
#+end_src
Here we receive a promised response from fetch. We then unwrap its inner value and
get our response object. After playing with it, we extract out the text (which
is a Promised string) and parse it into a json object. This entire expression
returns a Promised JSON object.

In this case we take a context, unwrap it, then return back the same context
with a transformed value.

We decide as we go, Our next computation is dependent on the value of the last.

Note how =async await= is basically do notation in this case
#+begin_src js
const getData = async (idx) => {
    let response = await fetch('http://localhost:8080/some-data');
    if (response.ok) {
        let text = await response.text();
        return JSON.parse(text);
    } else {
        throw new Error("An error has occured")
    }
};
#+end_src

=async= = =do=

=await= = =<-=

*** Why did I write this?
This is an explainer I have done, less because I want to try and be the one to
tackle the monad fallacy but because its fun and a good way to help me solidify
what I know. Plus it may start to
help build intuitions on these types. Though it must be said

#+begin_quote
There is no royal road to Haskell. â€”Euclid
#+end_quote

The best way to learn is to get your hands on them and play with them. No amount
of theory will do you any good unless you put these ideas into practice. Once
you do you start to see the patterns and then you can really get into the meat
of them and become an epik haskeller.
Some of the resources I really like include [[https://wiki.haskell.org/Typeclassopedia][The Typeclassopedia]], [[https://www.youtube.com/watch?v=fCoQb-zqYDI][This video on
the IO monad,]] this [[https://www.youtube.com/watch?v=N9RUqGYuGfw][video implementing a json parser in haskell]] and [[https://www.cis.upenn.edu/~cis1940/spring13/lectures.html][this course
from the University of Pennsylvania]].
Though it did not really begin to click until I started playing with Async in
Dart.

Hopefully this is helpful and or interesting. If I have made a mistake or you
want to discuss this [[mailto:jeetelongname@gmail.com][my email is here!]]
*** Footnotes
[fn:1] =g <$> Just 1= will return a function with the rest of the inputs wrapped
in a context. We need to remember that haskell is curried by default.
So if we have a type like this =g :: a -> a -> a -> a= we /really/ mean
=g :: a -> (a -> (a -> a))=. So when we reflect on the type of =<$> :: (a -> b)
-> f a -> f b= we can see that the rest of our function will be "swallowed"
b thus we get the type =g <$> :: f a -> f (a -> a -> a)=
** TODO Web scripting with ruby :opinion:programming:ruby:
** TODO Recreating the JS object system in ruby :ruby:javascript:oop:hack:programming:
:PROPERTIES:
:EXPORT_FILE_NAME: js-oop-ruby
:EXPORT_DATE: 2023-03-04
:END:
I had a funky idea, why not try and re create the js object system in ruby?
Why? well because we can.
This idea dawned on me when I realised I can add the functionality of property
like accesses to hash values using method missing.
#+begin_src ruby :tangle test.rb
class Hash
  def method_missing(prop, *args, &block)
    self[prop]
  end
end

hash = {
  hello: "hello is not a method ðŸ˜±",
}

puts hash.hello #=>  "hello is not a method ðŸ˜±"
#+end_src
Ignoring the method definition this looks a lot like javascript. and now I want to
see how far we can take it.

*** Some expectations
Now this will not lead to a full look alike of Javascripts object system. we can
get close but we are still limited by rubys syntax. In any case I think we can
create something that works a lot like the function and learn something along
the way!

*** Why javascripts object system is special
Lets take a minute to discuss javascripts object system.
JS is interesting because you do not need to go through classes to make objects.

*** Properties
Properties are our object attributes, they are our values, they can be read and
written too
#+begin_src javascript
obj = {
    first: "Joe",
    last: "mama"
}

console.log(obj.first) // => Joe
obj.last = "Son"
console.log(obj.last) // => Son
#+end_src
We can already get our properties, but we need to be able to set them.
Now in a pitiful language we would be stumped but not in ruby. Here setting
attributes is also a method that can be caught with ~method_missing~!

#+begin_src ruby
class Hash
  def method_missing(prop, *args)
    puts prop
  end
end

hash = {hello: "hi"}
hash.hello = "greetings" # => :hello=
#+end_src
as you can see, its just our method name with an equals sign appended too it.
check for that and we can set the property in question

#+begin_src ruby
class Hash
  def method_missing(prop, *args, &block)
   if prop.end_with? '='
     self[prop.to_s.delete_suffix('=').to_sym] = args.first
   else
     self[prop]
   end
  end
end

hash = {hello: "Hi"}
puts hash.hello # => "Hi"
hash.hello = "greetings"
puts hash.hello # => "greetings"
#+end_src

and just like that we can now get and set properties.

*** Methods
Methods are a little more interesting, Methods are properties that are
functions. The way they access the object is through the use of the ~this~ keyword.

#+begin_src js
obj = {
  first: "Joe",
  last: "Mama",
  full () {
    return `${this.first} ${this.last}`
  }
}

console.log(obj.full()) // => Joe Mama
#+end_src

Now this is a trivial case but methods can do all sorts of things, not only
access our properties but set them with arguments taken in from the caller.
All of this hinges on accessing the special variable...
**** ~This~
~this~ in js is an implicit and usually hidden arguments to all functions (except
arrow functions). It contains a reference to the object we are working on, You
can think of it like ~self~ in languages such as python and ruby.

~this~ can be passed in explicitly by using the ~.call~ method on the function like
so. In fact the ~obj.method()~ is just syntax sugar for the ~.call~ method.

#+begin_src js
obj.full() == obj.full.call(obj) // => true
#+end_src

This is visually similar to python. The only difference being that the
method definitions need to take in an implicit self argument as there first
positional argument.

#+begin_src python
class Person():
    def method(self, *args): # explit self argument
        return args

Person().method(1,2,3) # implict self passed in when called.
#+end_src

We can actually implement the python style of "this passing" relatively simply,
using lambdas and currying.

#+begin_src ruby :tangle test.rb
class Hash

  def method_missing(prop, *args)
    if prop.end_with?("=") # check if its a set
      self[prop.to_s.delete_suffix('=').to_sym] = args.first
    elsif (accessed_prop = self[prop]).instance_of? Proc
      # curry the method and then call it with self.
      # This returns another method which can take the rest of the arguments
      accessed_prop.curry.call(self)
    else
      accessed_prop
    end
  end

end

hash = { hello: 'Hi',
         greet: ->(this, name, l_name) { puts "#{this.hello}, #{name}, #{l_name}" } }


hash.hello = 'greetings'
puts hash.greet.('Joe', 'Mama') # => "greetings, Joe Mama"
#+end_src

**** Getters and Setters
*** Prototypes
** DONE The Reader Applicative and abstraction :haskell:programming:
CLOSED: [2023-04-10 Mon 02:43]
:PROPERTIES:
:EXPORT_DATE: 2023-04-08
:EXPORT_FILE_NAME: the-reader-monad-and-abstraction
:END:

Now this is not a haskell blog site but this is the second interesting thing
haskell has offered me.

Today we are discussing the curious nature of the Reader monad
(well the Reader applicative functor as I don't plan on delving into the
monad aspects a terrible amount)

To do this we will be discussing this pairs function.
#+begin_src haskell
pairs :: [a] -> [(a, a)]
pairs = zip <*> tail
#+end_src
On the surface its all weird and magical, but we will walk through the types and
the implementations so that we can maybe pick up an intuition on how this works
in general.

Now this function takes in a list and constructs a list of pairs, where the
second slot is the item over in the list from the first slot.
We can define it like this.
#+begin_src haskell :results output
pairs lst = zip lst (tail lst)

print $ [1..5]
print $ pairs [1..5]
#+end_src

: [1,2,3,4,5]
: [(1,2),(2,3),(3,4),(4,5)]

Now the question becomes, how does the first become the second using the Reader
applicative? How does the type work out in such a neat fashion? How does this really
abstract thing turn into something so concrete and useful? Well fear not dear
/reader/ we will answer these questions in due course.

*** How do these types work out?
Lets start off with the types
#+begin_src haskell
(<*>) :: Applicative m => m (a -> b) -> m a -> m b
#+end_src
This is the general type of the ~ap~ operator but in this case we are working with
the Reader applicative. In that case we need to see what it looks like when we
collapse the constraint.
#+begin_src haskell
(<*>) :: (r -> (a -> b)) -- (1)
      -> (r -> a)        -- (2)
      -> (r -> b)        -- (3)
#+end_src

To anyone who has worked with haskell a little bit, this should be /readable/.
1) is a function that takes in a value ~r~ and returns a function from ~a~ to ~b~
2) is a function from ~r~ to ~a~
3) is a function from ~r~ to ~b~. This is our return value.

where ~r~ ~a~ and ~b~ are type variables that will collapse as we apply arguments.
Note how our context is this ~(r -> ...)~ function. This means ours functions have
to take in the same first argument. You can intuit this as an "environment"
these functions take in, though we will discuss the uses of the Reader monad in
a bit.

We can actually clean this up a little bit, the ~->~ operator is right associative
meaning ~a -> b -> c -> d~ is the same as ~a -> (b -> (c -> d))~.
With this knowledge in hand our type before turns into.
#+begin_src haskell
(<*>) :: (r -> a -> b)
      -> (r -> a)
      -> r
      -> b
#+end_src

Here we can see something, our first argument is a function from ~r~ to ~a~ to ~b~,
our, second argument is a function from ~r~ to ~a~, This suggests we will combine
these functions so that the second argument to the first function is the result
of the second function (wordy I known). We also see how the return type ~b~ in the
first function is also the return type of the ~ap~ operator itself. This type is
pretty good at hinting both what this function takes in, and also how its
combining our arguments under the hood.

Now lets have a look at the types of ~zip~ and ~tail~
#+begin_src haskell
zip :: [a'] -> [b'] -> [(a', b')]
tail :: [a'] -> [a']
#+end_src

We can see both of these functions take in an ~[a']~ and then do something with
that. In other words our ~[a']~ becomes our ~r~. We can continue this process of
subbing types into our ~ap~ operator.
#+begin_src haskell
zip :: [a'] -> [b'] -> [(a', b')]
  thus
    r :: [a']
    a :: [b']
    b :: [(a', b')]
#+end_src

When we fill in our type with this information we can see our type popping out.
#+begin_src haskell
(zip <*>) :: ([a'] -> [b']) -> [a'] -> [(a', b')]
#+end_src

adding ~tail~ into the mix constrains the type of ~b'~ even further
#+begin_src haskell
tail :: [a'] -> [a']
  thus
     b' :: a'
#+end_src

applying this gives us our final type.
#+begin_src haskell
(zip <*> tail) :: [a'] -> [(a', a')]
#+end_src

Congrats, we have now manually done the job of the haskell type checker.
Hopefully now we now see how just by following the types and using abstractions
we have come back to the /type/ of thing we want to do. This is nice and all but
what about the actual implementation? the type is useless if it does not follow
our logic.

*** Why does the implementation work out?
the implementation of our ~ap~ operator for our Reader Applicative is as follows
#+begin_src haskell
(<*>) :: (r -> a -> b) -> (r -> a) -> r -> b
(<*>) f g r = f r (g r)
#+end_src

If we sub in our functions, we see our implementation pop out.
#+begin_src haskell
(<*>) zip tail lst :: [(a, a)]
(<*>) zip tail lst = zip lst (tail lst)
#+end_src

This leads us back to ~pairs = zip <*> tail~, which becomes our final implementation.

*** So now why does the reader monad exist?
Before we delve into that, we need discuss why we use applicatives and monads.
This was discussed in more detail in my [[file:/blog/posts/understanding-monads][understanding monads post]]
but here is a smaller run down.

An applicative functor allows us to compose contexts together into larger ones,
like we have seen. It allows for a lot of very interesting abstractions such as
parser combinators [fn:1] as well as many other use cases (note that all monads
you have played with also are applicatives). We see here how we have taken two
functions that take in the same first argument and use the reader applicative to
combine them into something larger. This scales.

#+begin_src haskell
zip3 :: [a] -> [b] -> [c] -> [(a, b, c)]
(zip3 <*>) :: ([a] -> [b]) -> [a] -> [c] -> [(a, b, c)]
(zip3 <*> map show) :: Show a => [a] -> [c] -> [(a, String, c)]
(zip3 <*> map show <*> map even) :: (Show a, Integral a) => [a] -> [(a, String, Bool)]
#+end_src

Here we essentially collect transformations of a list of type ~[a]~ Each function
on the left hand side receives this ~[a]~ but its the responsibility of the left
most function to collect it all together. This is a small contrived example, yet
the rules here would apply to any set of functions that take in the
same first argument.

Here we have a type with three parameters, we have functions that
extract out the information from a single string.
#+begin_src haskell
data Person = Person {name :: String, age :: Int, job :: String}

constructType :: String -> Person
constructType str = Person
                        (extractName str)
                        (extractAge str)
                        (extractJob str)
#+end_src
but now instead of passing in str manually we can use this Reader applicative to pass
this "environment" implicitly.

#+begin_src haskell
constructType :: String -> Person
constructType = Person <$> extractName <*> extractAge <*> extractJob
#+end_src

Again here follow the types. ~<$>~ is fmap, it lifts ~Person~ from a simple function
to a function that works with our Reader applicative.
#+begin_src haskell
(Person <$>) :: r -> String -> r -> (Int -> String -> Person)
#+end_src

We can then keep on adding functions with the use of our ~<*>~ operator like so

#+begin_src haskell
(Person <$>) :: r -> String -> r -> (Int -> String -> Person)
(Person <$> extractName <*>) :: r -> Int -> (String -> Person)
(Person <$> extractName <*> extractAge) :: r -> String -> Person
(Person <$> extractName <*> extractAge <*> extractJob) :: r -> Person
#+end_src


We take this further with monads, where we can use the latter computation to
inform the next. It allows us to combine these computations together using
context.

Its why the IO monad works so nicely. With the Reader monad it allows us to
compose together computations which all need some kind of shared read only state. Useful
when passing around things like app configurations (Values such as database
configuration or network settings that only become known at deploy time), or
something like react props

This post only really focused on the Reader applicative, If you want to see how
the reader /monad/ have a look at [[https://engineering.dollarshaveclub.com/the-reader-monad-example-motivation-542c54ccfaa8][this post from dollar shave club]].

*** The neatness of abstraction.
We have now used abstract tools to solve our concrete problems, Why is this
neat? Well now that we have expressed our solution in terms of this abstraction,
we can use all of the tools and types of this abstraction to aid us further.

take for example the function ~sequenceA~
#+begin_src haskell
sequenceA :: (Traversable t, Applicative f) => t (f a) -> f (t a)
#+end_src

here we can see it essentially can turn a type inside out, Now this may not seem
useful now but imagine what it would look like if we collapse the constraints.

#+begin_src haskell
sequenceA :: [r -> a] -> r -> [a]
#+end_src

Here we have a function that takes in a list of functions from ~r~ to ~a~ and then
it returns a function from ~r~ to ~[a]~

In other words, we can perform a set of transformations on a single value.

#+begin_src haskell
sequenceA [(+1), (+2), (+3)] 1
#+end_src

| 2 | 3 | 4 |

This may seem contrived but you can imagine use cases. We need to pass a user
given value through a gauntlet of checks. or we take in a value and need multipe
permutations of it and so on. I am sure that people are more creative than me.

Just by re-framing our problem using this abstraction, we have turned
something pretty manual and "low level" into something smaller, easier to extend
and nicer, and thats pretty neat.

*** Conclusion

Hopefully now you have a small intuition on the Reader Applicitive, The Reader
Monad is another beast but now you have the basics of the type out of the way
you can pick up that a with a little less head scratching.

Again this was not written to be useful but if you did find it useful feel free
to email me, (its somewhere on this site).

*** Appendix
So there is actually another version of the ~ap~ operator that is implemented in
terms of the Reader monad
#+begin_src haskell
pairs = ap zip tail
#+end_src
This is a historical artifact as Monads are older than Applicatives, but
it means we now have another way of framing the problem. As the type is
essentially the same (Just constrained to Monads) all of the type work we did
still /applies/ but the implementation and how we get back to our first solution
is interesting.

the implementation of ap is as follows
#+begin_src haskell
ap m1 m2 = do { x1 <- m1; x2 <- m2; return (x1 x2) }
#+end_src
as do notation is syntax sugar for ~>>=~ lets get rid of it
#+begin_src haskell
ap m1 m2 = m1 >>= (\x1 -> m2 >>= (\x2 -> return (x1 x2)))
#+end_src

The implementation of ~>>=~ and ~return~ are as follows
#+begin_src haskell
(>>=)  :: (r -> a) -> (a -> r -> b) -> r -> b
f >>= k = \r -> k (f r) r

return :: a -> r -> a
return = const
#+end_src

With this we can start to sub
#+begin_src haskell
-- return = const
ap zip tail = zip >>= (\x1 -> tail >>= (\x2 -> const (x1 x2)))
-- sub inner >>=
ap zip tail = zip >>= (\x1 -> (\r2 -> (\x2 -> const (x1 x2)) (tail r2) r2)
-- sub outer >>=
ap zip tail = (\r1 -> (\x1 -> (\r2 -> (\x2 -> const (x1 x2)) (tail r2) r2)) (zip r1) r1)
-- move r1 to the left hand side
ap zip tail r1 = (\x1 -> (\r2 -> (\x2 -> const (x1 x2)) (tail r2) r2)) (zip r1) r1
-- replace x1 with (zip r1)
ap zip tail r1 = (\r2 -> (\x2 -> const ((zip r1) x2)) (tail r2) r2) r1
-- replace x2 with (tail r2)
ap zip tail r1 = (\r2 -> const ((zip r1) (tail r2)) r2) r1
-- replace r2 with r1
ap zip tail r1 = const ((zip r1) (tail r1)) r1
-- const x = (\y -> x)
ap zip tail r1 = (\c1 -> ((zip r1) (tail r1))) r1
-- replace c1 with r1
ap zip tail r1 = ((zip r1) (tail r1))
-- clean up
ap zip tail r = (zip r) (tail r)
#+end_src

Easy to read, I know. This took me a while to work out but playing with it
helped quite a bit.
*** Footnotes
[fn:1] For those out of the loop, Parser combinators is a way to build up a
parser by composing smaller parsers together. [[https://www.youtube.com/watch?v=N9RUqGYuGfw][This video by the Tsoding really
helped me pick it up]]. Its also the basis for libraries such as [[https://hackage.haskell.org/package/parsec][Parsec]] and
other libraries that follow in its wake
** TODO Ox Hugo is pretty nice :blog:hugo:org:emacs:
:PROPERTIES:
:EXPORT_DATE: 2023-05-22
:EXPORT_FILE_NAME: ox-hugo-testimonial
:END:

I have been using [[https://ox-hugo.scripter.co/][ox-hugo]] to write this blog for a little bit now, Not to spoil
the review ðŸ˜‰ but its been a pretty smooth experience. I wanted to discuss some
of the great aspects, some of the downsides and some of the tweaks to make it a
seamless experience.

*** The good
Ox hugo has turned a mess of markdown files into a single neat org file (that
then tangles to that mess of markdown files). In short it has made blogging fun
again for me.
**** Org
The reason I like org is not really the syntax, though i also do prefer the
syntax. Org has fantastic tooling an intergration with emacs that just makes it
a joy to write. From its ability to guess the next opening syntax of things like
headings, to the intuitive commands to manipulate those elements. This is not a
review of org mode but to say its not part of the reason I switched would

*** The eh
*** The tweaks
*** Conclusions

*** Footnotes

* COMMENT Local Variables :ARCHIVE:
# Local Variables:
# org-export-with-author: nil
# org-log-done: 'time
# eval: (org-hugo-auto-export-mode)
# End:
